{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 11:12:38.722615: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-10 11:12:38.722933: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-10 11:12:38.724713: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-10 11:12:38.729477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733825558.737615   86449 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733825558.740029   86449 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-10 11:12:38.748980: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "\n",
    "# Ursprünglicher Datenordner\n",
    "original_dir = pathlib.Path(\"Data\")  # Oberordner der Kategorien\n",
    "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")  # Zielbasisordner\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    # Kategorien (Ordner: Cat und Dog)\n",
    "    for category in (\"Cat\", \"Dog\"):\n",
    "        # Neues Zielverzeichnis erstellen\n",
    "        dir = new_base_dir / subset_name / category.lower()  # Kategorienamen in Kleinbuchstaben\n",
    "        os.makedirs(dir, exist_ok=True)  # Ordner erstellen, falls nicht vorhanden\n",
    "\n",
    "        # Bilder dieser Kategorie auswählen\n",
    "        fnames = [f\"{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            # Quell- und Zielpfade definieren\n",
    "            src = original_dir / category / fname\n",
    "            dst = dir / fname\n",
    "\n",
    "            # Datei kopieren, wenn sie existiert\n",
    "            if src.exists():\n",
    "                shutil.copyfile(src, dst)\n",
    "\n",
    "# Teilmengen erstellen\n",
    "make_subset(\"train\", start_index=0, end_index=1000)\n",
    "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "make_subset(\"test\", start_index=1500, end_index=2500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Python Second Edititon (2021)\n",
    "---\n",
    "\n",
    "Kapitel 8: Introduction to deep learning for computer vision\n",
    "\n",
    "*S. 202* \n",
    "\n",
    "Listing 8.1 Instantiating a small convnet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Seite 204*\n",
    "\n",
    "Listing 8.3 Training the convnet on MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "loss=\"sparse_categorical_crossentropy\",\n",
    "metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S.204 \n",
    "\n",
    "Listing 8.4 Evaluating the convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*S. 210*\n",
    "\n",
    "\n",
    "Listing 8.5 An incorrectly structured convnet missing its max-pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model_no_max_pool = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_max_pool.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog vs Cats\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beispiel Modelle um ein Covnet aufzubauen\n",
    "---\n",
    "*S.216*\n",
    "\n",
    "Listing 8.7 Instantiating a small convnet for dogs vs. cats classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Model: convnet_from_scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1733825567.902531   86449 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,545</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m178\u001b[0m, \u001b[38;5;34m178\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,545\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">991,041</span> (3.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m991,041\u001b[0m (3.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">991,041</span> (3.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m991,041\u001b[0m (3.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing 8.8 Configuring the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "optimizer=\"rmsprop\",\n",
    "metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### image_dataset_from_directory: \n",
    "Ein Aufruf von \n",
    "- *image_dataset_from_directory(main_directory, labels='inferred')* \n",
    "\n",
    "gibt einen *tf.data.Dataset* zurück, der Stapel von Bildern aus den Unterverzeichnissen *class_a* und *class_b* zusammen mit den Labels 0 und 1 liefert (0 entspricht class_a und 1 entspricht class_b).\n",
    "\n",
    "- Supported image formats: .jpeg, .jpg, .png, .bmp, .gif. Animated gifs are truncated to the first frame.\n",
    "\n",
    "Paras:\n",
    "1. directory: \n",
    "- Verzeichnis, in dem sich die Daten befinden. Wenn labels „inferred“ (abgeleitet) ist, sollte es Unterverzeichnisse enthalten, die jeweils Bilder für eine Klasse enthalten. Andernfalls wird die Verzeichnisstruktur ignoriert.\n",
    "\n",
    "2. labels:\n",
    "- Entweder „inferred“ (Bezeichnungen werden aus der Verzeichnisstruktur generiert), None (keine Bezeichnungen) oder eine Liste/ein Tupel von ganzzahligen Bezeichnungen, die so groß sind wie die Anzahl der im Verzeichnis gefundenen Bilddateien. Die Bezeichnungen sollten nach der alphanumerischen Reihenfolge der Pfade der Bilddateien sortiert sein (in Python über os.walk(directory) ermittelt).\n",
    "3. image_size:    \n",
    "- image_size=(180, 180),  Größe der Bilder, auf die sie beim Laden skaliert werden\n",
    "\n",
    "4. batch_size:\n",
    "batch_size=32\n",
    "Anzahl der Bilder pro Batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- base_dir / \"train\", base_dir / \"validation\", base_dir / \"test\": Diese Verzeichnisse enthalten die Bilddaten, die für das Training, die Validierung und das Testen des Modells verwendet werden.\n",
    "- image_size=(180, 180): Jedes Bild wird auf eine Größe von 180x180 Pixeln skaliert, da CNNs eine feste Eingabegröße benötigen. Dies ist die Größe, die das Modell erwartet.\n",
    "- batch_size=32: Die Daten werden in Batches von je 32 Bildern verarbeitet. Das bedeutet, dass beim Training in jedem Schritt 32 Bilder gleichzeitig verarbeitet werden.\n",
    "- train_dataset, validation_dataset, test_dataset: Diese Objekte sind TensorFlow Dataset-Objekte, die die entsprechenden Bilddaten und Labels enthalten. Sie sind so strukturiert, dass sie effizient durch die Daten iterieren können, um sie an das Modell zu übergeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*S. 217*\n",
    "\n",
    "Listing 8.9 Using image_dataset_from_directory to read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1987 files belonging to 2 classes.\n",
      "Found 993 files belonging to 2 classes.\n",
      "Found 1987 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    \"cats_vs_dogs_small/train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "    \n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    \"cats_vs_dogs_small/validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    \"cats_vs_dogs_small/test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for data_batch, labels_batch in train_dataset:: Diese Schleife iteriert durch den train_dataset, der aus Batches von Bildern und den zugehörigen Labels besteht.\n",
    "\n",
    "    - In jedem Schritt der Schleife werden ein data_batch (Bilder) und ein labels_batch (Labels) geladen und zur Verfügung gestellt.\n",
    "\n",
    "- data_batch.shape: Dies gibt die Form des data_batch-Arrays aus. Da die Batch-Größe 32 ist, werden die Daten in einem 4D-Tensor organisiert:\n",
    "\n",
    "    - (32, 180, 180, 3) bedeutet:\n",
    "        - 32: Die Batch-Größe (32 Bilder).\n",
    "        - 180, 180: Die Höhe und Breite der Bilder (180x180 Pixel).\n",
    "        - 3: Die Anzahl der Farbkanäle (RGB).\n",
    "\n",
    "- labels_batch.shape: Dies gibt die Form des labels_batch-Arrays aus. Da es sich bei der Klassifikation wahrscheinlich um eine Multiklassen-Aufgabe handelt, ist die Form (32,), was bedeutet, dass jedes der 32 Bilder mit einem entsprechenden Label verknüpft ist.\n",
    "\n",
    "    - Wenn labels=\"inferred\" verwendet wird, wird davon ausgegangen, dass das Verzeichnis so strukturiert ist, dass die Ordnernamen die Klassennamen oder Labels sind. Zum Beispiel könnte ein Ordner cat für Bilder der Klasse \"Katze\" und ein Ordner dog für Bilder der Klasse \"Hund\" stehen.\n",
    "\n",
    "- break: Der break-Befehl unterbricht die Schleife nach dem ersten Batch. Das bedeutet, dass nur das erste Batch von 32 Bildern und Labels verarbeitet wird und anschließend der Code gestoppt wird. Normalerweise würde die Schleife ohne break durch alle Batches des Datensatzes iterieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*S. 219*\n",
    "\n",
    "Listing 8.10 Displaying the shapes of the data and labels yielded by the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (32, 180, 180, 3)\n",
      "labels batch shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_dataset:\n",
    "    print(\"data batch shape:\", data_batch.shape)\n",
    "    print(\"labels batch shape:\", labels_batch.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks ModelCheckpoint-Callback der dafür sorgt, dass das MOdell während des trainings gespeichert wird, aber nur unter bestimmten bediungen.\n",
    "\n",
    "1. keras.callbacks.ModelCheckpoint\n",
    "- ModelCheckpoint ist ein Callback in Keras, das während des Trainings eingesetzt wird, um das Modell nach jedem Trainigsepoch zu speichern. Dieser Callback kann so konfiguriert werden, dass das Modell nur dann gespeichert wird, wenn es eine bestimmte Bedingung erfüllt wird. (z.b wenn sich das Modell verbesser)\n",
    "- Der Callback wird an die Methode *fit()* des Modells übergeben, und zwar als Teil der Liste von Callbacks, die das Modell während des Trainings anwendet. Das Bedeutet, dass bei jedem Epochenergebnis überprüft wird, ob das Modell gespeichert werden soll.\n",
    "\n",
    "2. Parameter des ModelCheckpoint-Callbacks\n",
    "- filepath= \"convnet_from_scratch.keras\":\n",
    "    - Dateipfad wo das Modell gespeichert werden soll. Diese Datei enthält **alle** Modellgewichte sowie die Modellarchitektur und kann später für das Laden des Modells verwendet werden.\n",
    "\n",
    "    - Der Dateiname kann auch die Epochenummer beinhalten \"model_epoch_{epoch}.keras\"\n",
    "- save_best_only=True\n",
    "    - Modelle werden nur gespeichert wenn sich das Modell verbessert. Nur das beste Modell basierend auf dem beobachteten Kriterium wird gespeichert.\n",
    "    Auf *false* gesetzt wird wprde das Modell nach jeder Epoche gespeichert werden unabhängig davon ob sich die Leistung verbessert hat oder nicht.\n",
    "\n",
    "- monitor =\"val_loss\"\n",
    "    - Überwachung der Metrik die während des Training überwacht werden soll. In unseren Fall die Validierungsdaten *(val_loss)*\n",
    "    - Das Modell wird nur gespeichert, wenn der val_loss in einer Epoche besser wird als der zuvor beste Wert.\n",
    "    - Sie können auch andere Metriken überwachen, wie z. B. accuracy oder val_accuracy, je nachdem, welche Metrik für Ihr Modell wichtig ist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speicherung des Models\n",
    "\n",
    "*S. 219*\n",
    "\n",
    "Listing 8.11 Fitting the model using a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model/convnet_from_scratch.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m62/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.4888 - loss: 0.7034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 125ms/step - accuracy: 0.4893 - loss: 0.7031 - val_accuracy: 0.5025 - val_loss: 0.6921\n",
      "Epoch 2/5\n",
      "\u001b[1m62/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5607 - loss: 0.6918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - accuracy: 0.5609 - loss: 0.6917 - val_accuracy: 0.6224 - val_loss: 0.6601\n",
      "Epoch 3/5\n",
      "\u001b[1m62/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6095 - loss: 0.6664"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - accuracy: 0.6096 - loss: 0.6663 - val_accuracy: 0.6485 - val_loss: 0.6388\n",
      "Epoch 4/5\n",
      "\u001b[1m62/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6451 - loss: 0.6288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 122ms/step - accuracy: 0.6454 - loss: 0.6287 - val_accuracy: 0.5418 - val_loss: 1.0411\n",
      "Epoch 5/5\n",
      "\u001b[1m62/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.6694 - loss: 0.6401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - accuracy: 0.6700 - loss: 0.6388 - val_accuracy: 0.6415 - val_loss: 0.7041\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=5,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild ist gültig: 1500.jpg\n",
      "Bild ist gültig: 1501.jpg\n",
      "Bild ist gültig: 1502.jpg\n",
      "Bild ist gültig: 1503.jpg\n",
      "Bild ist gültig: 1504.jpg\n",
      "Bild ist gültig: 1505.jpg\n",
      "Bild ist gültig: 1506.jpg\n",
      "Bild ist gültig: 1507.jpg\n",
      "Bild ist gültig: 1508.jpg\n",
      "Bild ist gültig: 1509.jpg\n",
      "Bild ist gültig: 1510.jpg\n",
      "Bild ist gültig: 1511.jpg\n",
      "Bild ist gültig: 1512.jpg\n",
      "Bild ist gültig: 1513.jpg\n",
      "Bild ist gültig: 1514.jpg\n",
      "Bild ist gültig: 1515.jpg\n",
      "Bild ist gültig: 1516.jpg\n",
      "Bild ist gültig: 1517.jpg\n",
      "Bild ist gültig: 1518.jpg\n",
      "Bild ist gültig: 1519.jpg\n",
      "Bild ist gültig: 1520.jpg\n",
      "Bild ist gültig: 1521.jpg\n",
      "Bild ist gültig: 1522.jpg\n",
      "Bild ist gültig: 1523.jpg\n",
      "Bild ist gültig: 1524.jpg\n",
      "Bild ist gültig: 1525.jpg\n",
      "Bild ist gültig: 1526.jpg\n",
      "Bild ist gültig: 1527.jpg\n",
      "Bild ist gültig: 1528.jpg\n",
      "Bild ist gültig: 1529.jpg\n",
      "Bild ist gültig: 1530.jpg\n",
      "Bild ist gültig: 1531.jpg\n",
      "Bild ist gültig: 1532.jpg\n",
      "Bild ist gültig: 1533.jpg\n",
      "Bild ist gültig: 1534.jpg\n",
      "Bild ist gültig: 1535.jpg\n",
      "Bild ist gültig: 1536.jpg\n",
      "Bild ist gültig: 1537.jpg\n",
      "Bild ist gültig: 1538.jpg\n",
      "Bild ist gültig: 1539.jpg\n",
      "Bild ist gültig: 1540.jpg\n",
      "Bild ist gültig: 1541.jpg\n",
      "Bild ist gültig: 1542.jpg\n",
      "Bild ist gültig: 1543.jpg\n",
      "Bild ist gültig: 1544.jpg\n",
      "Bild ist gültig: 1545.jpg\n",
      "Bild ist gültig: 1546.jpg\n",
      "Bild ist gültig: 1547.jpg\n",
      "Bild ist gültig: 1548.jpg\n",
      "Bild ist gültig: 1549.jpg\n",
      "Bild ist gültig: 1550.jpg\n",
      "Bild ist gültig: 1551.jpg\n",
      "Bild ist gültig: 1552.jpg\n",
      "Bild ist gültig: 1553.jpg\n",
      "Bild ist gültig: 1554.jpg\n",
      "Bild ist gültig: 1555.jpg\n",
      "Bild ist gültig: 1556.jpg\n",
      "Bild ist gültig: 1557.jpg\n",
      "Bild ist gültig: 1558.jpg\n",
      "Bild ist gültig: 1559.jpg\n",
      "Bild ist gültig: 1560.jpg\n",
      "Bild ist gültig: 1561.jpg\n",
      "Bild ist gültig: 1562.jpg\n",
      "Bild ist gültig: 1563.jpg\n",
      "Bild ist gültig: 1564.jpg\n",
      "Bild ist gültig: 1565.jpg\n",
      "Bild ist gültig: 1566.jpg\n",
      "Bild ist gültig: 1567.jpg\n",
      "Bild ist gültig: 1568.jpg\n",
      "Bild ist gültig: 1569.jpg\n",
      "Bild ist gültig: 1570.jpg\n",
      "Bild ist gültig: 1571.jpg\n",
      "Bild ist gültig: 1572.jpg\n",
      "Bild ist gültig: 1573.jpg\n",
      "Bild ist gültig: 1574.jpg\n",
      "Bild ist gültig: 1575.jpg\n",
      "Bild ist gültig: 1576.jpg\n",
      "Bild ist gültig: 1577.jpg\n",
      "Bild ist gültig: 1578.jpg\n",
      "Bild ist gültig: 1579.jpg\n",
      "Bild ist gültig: 1580.jpg\n",
      "Bild ist gültig: 1581.jpg\n",
      "Bild ist gültig: 1582.jpg\n",
      "Bild ist gültig: 1583.jpg\n",
      "Bild ist gültig: 1584.jpg\n",
      "Bild ist gültig: 1585.jpg\n",
      "Bild ist gültig: 1586.jpg\n",
      "Bild ist gültig: 1587.jpg\n",
      "Bild ist gültig: 1588.jpg\n",
      "Bild ist gültig: 1589.jpg\n",
      "Bild ist gültig: 1590.jpg\n",
      "Bild ist gültig: 1591.jpg\n",
      "Bild ist gültig: 1592.jpg\n",
      "Bild ist gültig: 1593.jpg\n",
      "Bild ist gültig: 1594.jpg\n",
      "Bild ist gültig: 1595.jpg\n",
      "Bild ist gültig: 1596.jpg\n",
      "Bild ist gültig: 1597.jpg\n",
      "Bild ist gültig: 1598.jpg\n",
      "Bild ist gültig: 1599.jpg\n",
      "Bild ist gültig: 1600.jpg\n",
      "Bild ist gültig: 1601.jpg\n",
      "Bild ist gültig: 1602.jpg\n",
      "Bild ist gültig: 1603.jpg\n",
      "Bild ist gültig: 1604.jpg\n",
      "Bild ist gültig: 1605.jpg\n",
      "Bild ist gültig: 1606.jpg\n",
      "Bild ist gültig: 1607.jpg\n",
      "Bild ist gültig: 1608.jpg\n",
      "Bild ist gültig: 1609.jpg\n",
      "Bild ist gültig: 1610.jpg\n",
      "Bild ist gültig: 1611.jpg\n",
      "Bild ist gültig: 1612.jpg\n",
      "Bild ist gültig: 1613.jpg\n",
      "Bild ist gültig: 1614.jpg\n",
      "Bild ist gültig: 1615.jpg\n",
      "Bild ist gültig: 1616.jpg\n",
      "Bild ist gültig: 1617.jpg\n",
      "Bild ist gültig: 1618.jpg\n",
      "Bild ist gültig: 1619.jpg\n",
      "Bild ist gültig: 1620.jpg\n",
      "Bild ist gültig: 1621.jpg\n",
      "Bild ist gültig: 1622.jpg\n",
      "Bild ist gültig: 1623.jpg\n",
      "Bild ist gültig: 1624.jpg\n",
      "Bild ist gültig: 1625.jpg\n",
      "Bild ist gültig: 1626.jpg\n",
      "Bild ist gültig: 1627.jpg\n",
      "Bild ist gültig: 1628.jpg\n",
      "Bild ist gültig: 1629.jpg\n",
      "Bild ist gültig: 1630.jpg\n",
      "Bild ist gültig: 1631.jpg\n",
      "Bild ist gültig: 1632.jpg\n",
      "Bild ist gültig: 1633.jpg\n",
      "Bild ist gültig: 1634.jpg\n",
      "Bild ist gültig: 1635.jpg\n",
      "Bild ist gültig: 1636.jpg\n",
      "Bild ist gültig: 1637.jpg\n",
      "Bild ist gültig: 1638.jpg\n",
      "Bild ist gültig: 1639.jpg\n",
      "Bild ist gültig: 1640.jpg\n",
      "Bild ist gültig: 1641.jpg\n",
      "Bild ist gültig: 1642.jpg\n",
      "Bild ist gültig: 1643.jpg\n",
      "Bild ist gültig: 1644.jpg\n",
      "Bild ist gültig: 1645.jpg\n",
      "Bild ist gültig: 1646.jpg\n",
      "Bild ist gültig: 1647.jpg\n",
      "Bild ist gültig: 1648.jpg\n",
      "Bild ist gültig: 1649.jpg\n",
      "Bild ist gültig: 1650.jpg\n",
      "Bild ist gültig: 1651.jpg\n",
      "Bild ist gültig: 1652.jpg\n",
      "Bild ist gültig: 1653.jpg\n",
      "Bild ist gültig: 1654.jpg\n",
      "Bild ist gültig: 1655.jpg\n",
      "Bild ist gültig: 1656.jpg\n",
      "Bild ist gültig: 1657.jpg\n",
      "Bild ist gültig: 1658.jpg\n",
      "Bild ist gültig: 1659.jpg\n",
      "Bild ist gültig: 1660.jpg\n",
      "Bild ist gültig: 1661.jpg\n",
      "Bild ist gültig: 1662.jpg\n",
      "Bild ist gültig: 1663.jpg\n",
      "Bild ist gültig: 1664.jpg\n",
      "Bild ist gültig: 1665.jpg\n",
      "Bild ist gültig: 1666.jpg\n",
      "Bild ist gültig: 1667.jpg\n",
      "Bild ist gültig: 1668.jpg\n",
      "Bild ist gültig: 1669.jpg\n",
      "Bild ist gültig: 1670.jpg\n",
      "Bild ist gültig: 1671.jpg\n",
      "Bild ist gültig: 1672.jpg\n",
      "Bild ist gültig: 1673.jpg\n",
      "Bild ist gültig: 1674.jpg\n",
      "Bild ist gültig: 1675.jpg\n",
      "Bild ist gültig: 1676.jpg\n",
      "Bild ist gültig: 1677.jpg\n",
      "Bild ist gültig: 1678.jpg\n",
      "Bild ist gültig: 1679.jpg\n",
      "Bild ist gültig: 1680.jpg\n",
      "Bild ist gültig: 1681.jpg\n",
      "Bild ist gültig: 1682.jpg\n",
      "Bild ist gültig: 1683.jpg\n",
      "Bild ist gültig: 1684.jpg\n",
      "Bild ist gültig: 1685.jpg\n",
      "Bild ist gültig: 1686.jpg\n",
      "Bild ist gültig: 1687.jpg\n",
      "Bild ist gültig: 1688.jpg\n",
      "Bild ist gültig: 1689.jpg\n",
      "Bild ist gültig: 1690.jpg\n",
      "Bild ist gültig: 1691.jpg\n",
      "Bild ist gültig: 1692.jpg\n",
      "Bild ist gültig: 1693.jpg\n",
      "Bild ist gültig: 1694.jpg\n",
      "Bild ist gültig: 1695.jpg\n",
      "Bild ist gültig: 1696.jpg\n",
      "Bild ist gültig: 1697.jpg\n",
      "Bild ist gültig: 1698.jpg\n",
      "Bild ist gültig: 1699.jpg\n",
      "Bild ist gültig: 1700.jpg\n",
      "Bild ist gültig: 1701.jpg\n",
      "Bild ist gültig: 1702.jpg\n",
      "Bild ist gültig: 1703.jpg\n",
      "Bild ist gültig: 1704.jpg\n",
      "Bild ist gültig: 1705.jpg\n",
      "Bild ist gültig: 1706.jpg\n",
      "Bild ist gültig: 1707.jpg\n",
      "Bild ist gültig: 1708.jpg\n",
      "Bild ist gültig: 1709.jpg\n",
      "Bild ist gültig: 1710.jpg\n",
      "Bild ist gültig: 1711.jpg\n",
      "Bild ist gültig: 1712.jpg\n",
      "Bild ist gültig: 1713.jpg\n",
      "Bild ist gültig: 1714.jpg\n",
      "Bild ist gültig: 1715.jpg\n",
      "Bild ist gültig: 1716.jpg\n",
      "Bild ist gültig: 1717.jpg\n",
      "Bild ist gültig: 1718.jpg\n",
      "Bild ist gültig: 1719.jpg\n",
      "Bild ist gültig: 1720.jpg\n",
      "Bild ist gültig: 1721.jpg\n",
      "Bild ist gültig: 1722.jpg\n",
      "Bild ist gültig: 1723.jpg\n",
      "Bild ist gültig: 1724.jpg\n",
      "Bild ist gültig: 1725.jpg\n",
      "Bild ist gültig: 1726.jpg\n",
      "Bild ist gültig: 1727.jpg\n",
      "Bild ist gültig: 1728.jpg\n",
      "Bild ist gültig: 1729.jpg\n",
      "Bild ist gültig: 1730.jpg\n",
      "Bild ist gültig: 1731.jpg\n",
      "Bild ist gültig: 1732.jpg\n",
      "Bild ist gültig: 1733.jpg\n",
      "Bild ist gültig: 1734.jpg\n",
      "Bild ist gültig: 1735.jpg\n",
      "Bild ist gültig: 1736.jpg\n",
      "Bild ist gültig: 1737.jpg\n",
      "Bild ist gültig: 1738.jpg\n",
      "Bild ist gültig: 1739.jpg\n",
      "Bild ist gültig: 1740.jpg\n",
      "Bild ist gültig: 1741.jpg\n",
      "Bild ist gültig: 1742.jpg\n",
      "Bild ist gültig: 1743.jpg\n",
      "Bild ist gültig: 1744.jpg\n",
      "Bild ist gültig: 1745.jpg\n",
      "Bild ist gültig: 1746.jpg\n",
      "Bild ist gültig: 1747.jpg\n",
      "Bild ist gültig: 1748.jpg\n",
      "Bild ist gültig: 1749.jpg\n",
      "Bild ist gültig: 1750.jpg\n",
      "Bild ist gültig: 1751.jpg\n",
      "Bild ist gültig: 1752.jpg\n",
      "Bild ist gültig: 1753.jpg\n",
      "Bild ist gültig: 1754.jpg\n",
      "Bild ist gültig: 1755.jpg\n",
      "Bild ist gültig: 1756.jpg\n",
      "Bild ist gültig: 1758.jpg\n",
      "Bild ist gültig: 1759.jpg\n",
      "Bild ist gültig: 1760.jpg\n",
      "Bild ist gültig: 1761.jpg\n",
      "Bild ist gültig: 1762.jpg\n",
      "Bild ist gültig: 1763.jpg\n",
      "Bild ist gültig: 1764.jpg\n",
      "Bild ist gültig: 1765.jpg\n",
      "Bild ist gültig: 1766.jpg\n",
      "Bild ist gültig: 1767.jpg\n",
      "Bild ist gültig: 1768.jpg\n",
      "Bild ist gültig: 1769.jpg\n",
      "Bild ist gültig: 1770.jpg\n",
      "Bild ist gültig: 1771.jpg\n",
      "Bild ist gültig: 1772.jpg\n",
      "Bild ist gültig: 1773.jpg\n",
      "Bild ist gültig: 1774.jpg\n",
      "Bild ist gültig: 1775.jpg\n",
      "Bild ist gültig: 1776.jpg\n",
      "Bild ist gültig: 1777.jpg\n",
      "Bild ist gültig: 1778.jpg\n",
      "Bild ist gültig: 1779.jpg\n",
      "Bild ist gültig: 1780.jpg\n",
      "Bild ist gültig: 1781.jpg\n",
      "Bild ist gültig: 1782.jpg\n",
      "Bild ist gültig: 1783.jpg\n",
      "Bild ist gültig: 1784.jpg\n",
      "Bild ist gültig: 1785.jpg\n",
      "Bild ist gültig: 1786.jpg\n",
      "Bild ist gültig: 1787.jpg\n",
      "Bild ist gültig: 1788.jpg\n",
      "Bild ist gültig: 1789.jpg\n",
      "Bild ist gültig: 1790.jpg\n",
      "Bild ist gültig: 1791.jpg\n",
      "Bild ist gültig: 1792.jpg\n",
      "Bild ist gültig: 1793.jpg\n",
      "Bild ist gültig: 1794.jpg\n",
      "Bild ist gültig: 1795.jpg\n",
      "Bild ist gültig: 1796.jpg\n",
      "Bild ist gültig: 1797.jpg\n",
      "Bild ist gültig: 1798.jpg\n",
      "Bild ist gültig: 1799.jpg\n",
      "Bild ist gültig: 1800.jpg\n",
      "Bild ist gültig: 1801.jpg\n",
      "Bild ist gültig: 1802.jpg\n",
      "Bild ist gültig: 1803.jpg\n",
      "Bild ist gültig: 1804.jpg\n",
      "Bild ist gültig: 1805.jpg\n",
      "Bild ist gültig: 1806.jpg\n",
      "Bild ist gültig: 1807.jpg\n",
      "Bild ist gültig: 1808.jpg\n",
      "Bild ist gültig: 1809.jpg\n",
      "Bild ist gültig: 1810.jpg\n",
      "Bild ist gültig: 1811.jpg\n",
      "Bild ist gültig: 1812.jpg\n",
      "Bild ist gültig: 1813.jpg\n",
      "Bild ist gültig: 1814.jpg\n",
      "Bild ist gültig: 1815.jpg\n",
      "Bild ist gültig: 1816.jpg\n",
      "Bild ist gültig: 1817.jpg\n",
      "Bild ist gültig: 1818.jpg\n",
      "Bild ist gültig: 1819.jpg\n",
      "Bild ist gültig: 1820.jpg\n",
      "Bild ist gültig: 1821.jpg\n",
      "Bild ist gültig: 1822.jpg\n",
      "Bild ist gültig: 1823.jpg\n",
      "Bild ist gültig: 1824.jpg\n",
      "Bild ist gültig: 1825.jpg\n",
      "Bild ist gültig: 1826.jpg\n",
      "Bild ist gültig: 1827.jpg\n",
      "Bild ist gültig: 1828.jpg\n",
      "Bild ist gültig: 1829.jpg\n",
      "Bild ist gültig: 1830.jpg\n",
      "Bild ist gültig: 1831.jpg\n",
      "Bild ist gültig: 1832.jpg\n",
      "Bild ist gültig: 1833.jpg\n",
      "Bild ist gültig: 1834.jpg\n",
      "Bild ist gültig: 1835.jpg\n",
      "Bild ist gültig: 1836.jpg\n",
      "Bild ist gültig: 1837.jpg\n",
      "Bild ist gültig: 1838.jpg\n",
      "Bild ist gültig: 1839.jpg\n",
      "Bild ist gültig: 1840.jpg\n",
      "Bild ist gültig: 1841.jpg\n",
      "Bild ist gültig: 1842.jpg\n",
      "Bild ist gültig: 1843.jpg\n",
      "Bild ist gültig: 1844.jpg\n",
      "Bild ist gültig: 1845.jpg\n",
      "Bild ist gültig: 1846.jpg\n",
      "Bild ist gültig: 1847.jpg\n",
      "Bild ist gültig: 1848.jpg\n",
      "Bild ist gültig: 1849.jpg\n",
      "Bild ist gültig: 1850.jpg\n",
      "Bild ist gültig: 1851.jpg\n",
      "Bild ist gültig: 1852.jpg\n",
      "Bild ist gültig: 1853.jpg\n",
      "Bild ist gültig: 1854.jpg\n",
      "Bild ist gültig: 1855.jpg\n",
      "Bild ist gültig: 1856.jpg\n",
      "Bild ist gültig: 1857.jpg\n",
      "Bild ist gültig: 1858.jpg\n",
      "Bild ist gültig: 1859.jpg\n",
      "Bild ist gültig: 1860.jpg\n",
      "Bild ist gültig: 1861.jpg\n",
      "Bild ist gültig: 1862.jpg\n",
      "Bild ist gültig: 1863.jpg\n",
      "Bild ist gültig: 1864.jpg\n",
      "Bild ist gültig: 1865.jpg\n",
      "Bild ist gültig: 1866.jpg\n",
      "Bild ist gültig: 1867.jpg\n",
      "Bild ist gültig: 1868.jpg\n",
      "Bild ist gültig: 1869.jpg\n",
      "Bild ist gültig: 1870.jpg\n",
      "Bild ist gültig: 1871.jpg\n",
      "Bild ist gültig: 1872.jpg\n",
      "Bild ist gültig: 1873.jpg\n",
      "Bild ist gültig: 1874.jpg\n",
      "Bild ist gültig: 1875.jpg\n",
      "Bild ist gültig: 1876.jpg\n",
      "Bild ist gültig: 1877.jpg\n",
      "Bild ist gültig: 1878.jpg\n",
      "Bild ist gültig: 1879.jpg\n",
      "Bild ist gültig: 1880.jpg\n",
      "Bild ist gültig: 1881.jpg\n",
      "Bild ist gültig: 1882.jpg\n",
      "Bild ist gültig: 1883.jpg\n",
      "Bild ist gültig: 1884.jpg\n",
      "Bild ist gültig: 1885.jpg\n",
      "Bild ist gültig: 1886.jpg\n",
      "Bild ist gültig: 1887.jpg\n",
      "Bild ist gültig: 1888.jpg\n",
      "Bild ist gültig: 1889.jpg\n",
      "Bild ist gültig: 1890.jpg\n",
      "Bild ist gültig: 1891.jpg\n",
      "Bild ist gültig: 1892.jpg\n",
      "Bild ist gültig: 1893.jpg\n",
      "Bild ist gültig: 1894.jpg\n",
      "Bild ist gültig: 1895.jpg\n",
      "Bild ist gültig: 1896.jpg\n",
      "Bild ist gültig: 1897.jpg\n",
      "Bild ist gültig: 1898.jpg\n",
      "Bild ist gültig: 1899.jpg\n",
      "Bild ist gültig: 1900.jpg\n",
      "Bild ist gültig: 1901.jpg\n",
      "Bild ist gültig: 1902.jpg\n",
      "Bild ist gültig: 1903.jpg\n",
      "Bild ist gültig: 1904.jpg\n",
      "Bild ist gültig: 1905.jpg\n",
      "Bild ist gültig: 1906.jpg\n",
      "Bild ist gültig: 1907.jpg\n",
      "Bild ist gültig: 1908.jpg\n",
      "Bild ist gültig: 1909.jpg\n",
      "Bild ist gültig: 1910.jpg\n",
      "Bild ist gültig: 1911.jpg\n",
      "Bild ist gültig: 1912.jpg\n",
      "Bild ist gültig: 1913.jpg\n",
      "Bild ist gültig: 1915.jpg\n",
      "Bild ist gültig: 1916.jpg\n",
      "Bild ist gültig: 1917.jpg\n",
      "Bild ist gültig: 1918.jpg\n",
      "Bild ist gültig: 1919.jpg\n",
      "Bild ist gültig: 1920.jpg\n",
      "Bild ist gültig: 1921.jpg\n",
      "Bild ist gültig: 1922.jpg\n",
      "Bild ist gültig: 1923.jpg\n",
      "Bild ist gültig: 1924.jpg\n",
      "Bild ist gültig: 1925.jpg\n",
      "Bild ist gültig: 1926.jpg\n",
      "Bild ist gültig: 1927.jpg\n",
      "Bild ist gültig: 1928.jpg\n",
      "Bild ist gültig: 1929.jpg\n",
      "Bild ist gültig: 1930.jpg\n",
      "Bild ist gültig: 1931.jpg\n",
      "Bild ist gültig: 1932.jpg\n",
      "Bild ist gültig: 1933.jpg\n",
      "Bild ist gültig: 1934.jpg\n",
      "Bild ist gültig: 1935.jpg\n",
      "Bild ist gültig: 1938.jpg\n",
      "Bild ist gültig: 1939.jpg\n",
      "Bild ist gültig: 1940.jpg\n",
      "Bild ist gültig: 1941.jpg\n",
      "Bild ist gültig: 1942.jpg\n",
      "Bild ist gültig: 1943.jpg\n",
      "Bild ist gültig: 1944.jpg\n",
      "Bild ist gültig: 1945.jpg\n",
      "Bild ist gültig: 1946.jpg\n",
      "Bild ist gültig: 1947.jpg\n",
      "Bild ist gültig: 1948.jpg\n",
      "Bild ist gültig: 1949.jpg\n",
      "Bild ist gültig: 1950.jpg\n",
      "Bild ist gültig: 1951.jpg\n",
      "Bild ist gültig: 1952.jpg\n",
      "Bild ist gültig: 1953.jpg\n",
      "Bild ist gültig: 1954.jpg\n",
      "Bild ist gültig: 1955.jpg\n",
      "Bild ist gültig: 1956.jpg\n",
      "Bild ist gültig: 1957.jpg\n",
      "Bild ist gültig: 1958.jpg\n",
      "Bild ist gültig: 1959.jpg\n",
      "Bild ist gültig: 1960.jpg\n",
      "Bild ist gültig: 1961.jpg\n",
      "Bild ist gültig: 1962.jpg\n",
      "Bild ist gültig: 1963.jpg\n",
      "Bild ist gültig: 1964.jpg\n",
      "Bild ist gültig: 1965.jpg\n",
      "Bild ist gültig: 1966.jpg\n",
      "Bild ist gültig: 1967.jpg\n",
      "Bild ist gültig: 1968.jpg\n",
      "Bild ist gültig: 1969.jpg\n",
      "Bild ist gültig: 1970.jpg\n",
      "Bild ist gültig: 1971.jpg\n",
      "Bild ist gültig: 1972.jpg\n",
      "Bild ist gültig: 1973.jpg\n",
      "Bild ist gültig: 1974.jpg\n",
      "Bild ist gültig: 1975.jpg\n",
      "Bild ist gültig: 1976.jpg\n",
      "Bild ist gültig: 1977.jpg\n",
      "Bild ist gültig: 1978.jpg\n",
      "Bild ist gültig: 1979.jpg\n",
      "Bild ist gültig: 1980.jpg\n",
      "Bild ist gültig: 1981.jpg\n",
      "Bild ist gültig: 1982.jpg\n",
      "Bild ist gültig: 1983.jpg\n",
      "Bild ist gültig: 1984.jpg\n",
      "Bild ist gültig: 1985.jpg\n",
      "Bild ist gültig: 1986.jpg\n",
      "Bild ist gültig: 1987.jpg\n",
      "Bild ist gültig: 1988.jpg\n",
      "Bild ist gültig: 1989.jpg\n",
      "Bild ist gültig: 1990.jpg\n",
      "Bild ist gültig: 1991.jpg\n",
      "Bild ist gültig: 1992.jpg\n",
      "Bild ist gültig: 1993.jpg\n",
      "Bild ist gültig: 1994.jpg\n",
      "Bild ist gültig: 1995.jpg\n",
      "Bild ist gültig: 1996.jpg\n",
      "Bild ist gültig: 1997.jpg\n",
      "Bild ist gültig: 1998.jpg\n",
      "Bild ist gültig: 1999.jpg\n",
      "Bild ist gültig: 2000.jpg\n",
      "Bild ist gültig: 2001.jpg\n",
      "Bild ist gültig: 2002.jpg\n",
      "Bild ist gültig: 2003.jpg\n",
      "Bild ist gültig: 2004.jpg\n",
      "Bild ist gültig: 2005.jpg\n",
      "Bild ist gültig: 2006.jpg\n",
      "Bild ist gültig: 2007.jpg\n",
      "Bild ist gültig: 2008.jpg\n",
      "Bild ist gültig: 2009.jpg\n",
      "Bild ist gültig: 2010.jpg\n",
      "Bild ist gültig: 2011.jpg\n",
      "Bild ist gültig: 2012.jpg\n",
      "Bild ist gültig: 2013.jpg\n",
      "Bild ist gültig: 2014.jpg\n",
      "Bild ist gültig: 2015.jpg\n",
      "Bild ist gültig: 2016.jpg\n",
      "Bild ist gültig: 2017.jpg\n",
      "Bild ist gültig: 2018.jpg\n",
      "Bild ist gültig: 2019.jpg\n",
      "Bild ist gültig: 2020.jpg\n",
      "Bild ist gültig: 2022.jpg\n",
      "Bild ist gültig: 2023.jpg\n",
      "Bild ist gültig: 2024.jpg\n",
      "Bild ist gültig: 2025.jpg\n",
      "Bild ist gültig: 2026.jpg\n",
      "Bild ist gültig: 2027.jpg\n",
      "Bild ist gültig: 2028.jpg\n",
      "Bild ist gültig: 2029.jpg\n",
      "Bild ist gültig: 2030.jpg\n",
      "Bild ist gültig: 2031.jpg\n",
      "Bild ist gültig: 2032.jpg\n",
      "Bild ist gültig: 2033.jpg\n",
      "Bild ist gültig: 2034.jpg\n",
      "Bild ist gültig: 2035.jpg\n",
      "Bild ist gültig: 2036.jpg\n",
      "Bild ist gültig: 2037.jpg\n",
      "Bild ist gültig: 2038.jpg\n",
      "Bild ist gültig: 2039.jpg\n",
      "Bild ist gültig: 2040.jpg\n",
      "Bild ist gültig: 2041.jpg\n",
      "Bild ist gültig: 2042.jpg\n",
      "Bild ist gültig: 2043.jpg\n",
      "Bild ist gültig: 2044.jpg\n",
      "Bild ist gültig: 2045.jpg\n",
      "Bild ist gültig: 2046.jpg\n",
      "Bild ist gültig: 2047.jpg\n",
      "Bild ist gültig: 2048.jpg\n",
      "Bild ist gültig: 2049.jpg\n",
      "Bild ist gültig: 2050.jpg\n",
      "Bild ist gültig: 2051.jpg\n",
      "Bild ist gültig: 2052.jpg\n",
      "Bild ist gültig: 2053.jpg\n",
      "Bild ist gültig: 2054.jpg\n",
      "Bild ist gültig: 2055.jpg\n",
      "Bild ist gültig: 2056.jpg\n",
      "Bild ist gültig: 2057.jpg\n",
      "Bild ist gültig: 2058.jpg\n",
      "Bild ist gültig: 2059.jpg\n",
      "Bild ist gültig: 2060.jpg\n",
      "Bild ist gültig: 2061.jpg\n",
      "Bild ist gültig: 2062.jpg\n",
      "Bild ist gültig: 2063.jpg\n",
      "Bild ist gültig: 2064.jpg\n",
      "Bild ist gültig: 2065.jpg\n",
      "Bild ist gültig: 2066.jpg\n",
      "Bild ist gültig: 2067.jpg\n",
      "Bild ist gültig: 2068.jpg\n",
      "Bild ist gültig: 2069.jpg\n",
      "Bild ist gültig: 2070.jpg\n",
      "Bild ist gültig: 2071.jpg\n",
      "Bild ist gültig: 2072.jpg\n",
      "Bild ist gültig: 2073.jpg\n",
      "Bild ist gültig: 2074.jpg\n",
      "Bild ist gültig: 2075.jpg\n",
      "Bild ist gültig: 2076.jpg\n",
      "Bild ist gültig: 2077.jpg\n",
      "Bild ist gültig: 2078.jpg\n",
      "Bild ist gültig: 2079.jpg\n",
      "Bild ist gültig: 2080.jpg\n",
      "Bild ist gültig: 2081.jpg\n",
      "Bild ist gültig: 2082.jpg\n",
      "Bild ist gültig: 2083.jpg\n",
      "Bild ist gültig: 2084.jpg\n",
      "Bild ist gültig: 2085.jpg\n",
      "Bild ist gültig: 2086.jpg\n",
      "Bild ist gültig: 2087.jpg\n",
      "Bild ist gültig: 2088.jpg\n",
      "Bild ist gültig: 2089.jpg\n",
      "Bild ist gültig: 2090.jpg\n",
      "Bild ist gültig: 2091.jpg\n",
      "Bild ist gültig: 2092.jpg\n",
      "Bild ist gültig: 2093.jpg\n",
      "Bild ist gültig: 2094.jpg\n",
      "Bild ist gültig: 2095.jpg\n",
      "Bild ist gültig: 2096.jpg\n",
      "Bild ist gültig: 2097.jpg\n",
      "Bild ist gültig: 2098.jpg\n",
      "Bild ist gültig: 2099.jpg\n",
      "Bild ist gültig: 2100.jpg\n",
      "Bild ist gültig: 2101.jpg\n",
      "Bild ist gültig: 2102.jpg\n",
      "Bild ist gültig: 2103.jpg\n",
      "Bild ist gültig: 2104.jpg\n",
      "Bild ist gültig: 2105.jpg\n",
      "Bild ist gültig: 2106.jpg\n",
      "Bild ist gültig: 2107.jpg\n",
      "Bild ist gültig: 2108.jpg\n",
      "Bild ist gültig: 2109.jpg\n",
      "Bild ist gültig: 2110.jpg\n",
      "Bild ist gültig: 2111.jpg\n",
      "Bild ist gültig: 2112.jpg\n",
      "Bild ist gültig: 2113.jpg\n",
      "Bild ist gültig: 2114.jpg\n",
      "Bild ist gültig: 2115.jpg\n",
      "Bild ist gültig: 2116.jpg\n",
      "Bild ist gültig: 2117.jpg\n",
      "Bild ist gültig: 2118.jpg\n",
      "Bild ist gültig: 2119.jpg\n",
      "Bild ist gültig: 2120.jpg\n",
      "Bild ist gültig: 2121.jpg\n",
      "Bild ist gültig: 2122.jpg\n",
      "Bild ist gültig: 2123.jpg\n",
      "Bild ist gültig: 2124.jpg\n",
      "Bild ist gültig: 2125.jpg\n",
      "Bild ist gültig: 2126.jpg\n",
      "Bild ist gültig: 2127.jpg\n",
      "Bild ist gültig: 2128.jpg\n",
      "Bild ist gültig: 2129.jpg\n",
      "Bild ist gültig: 2130.jpg\n",
      "Bild ist gültig: 2131.jpg\n",
      "Bild ist gültig: 2132.jpg\n",
      "Bild ist gültig: 2133.jpg\n",
      "Bild ist gültig: 2134.jpg\n",
      "Bild ist gültig: 2135.jpg\n",
      "Bild ist gültig: 2136.jpg\n",
      "Bild ist gültig: 2137.jpg\n",
      "Bild ist gültig: 2138.jpg\n",
      "Bild ist gültig: 2139.jpg\n",
      "Bild ist gültig: 2140.jpg\n",
      "Bild ist gültig: 2141.jpg\n",
      "Bild ist gültig: 2142.jpg\n",
      "Bild ist gültig: 2143.jpg\n",
      "Bild ist gültig: 2144.jpg\n",
      "Bild ist gültig: 2145.jpg\n",
      "Bild ist gültig: 2146.jpg\n",
      "Bild ist gültig: 2147.jpg\n",
      "Bild ist gültig: 2148.jpg\n",
      "Bild ist gültig: 2149.jpg\n",
      "Bild ist gültig: 2150.jpg\n",
      "Bild ist gültig: 2151.jpg\n",
      "Bild ist gültig: 2152.jpg\n",
      "Bild ist gültig: 2153.jpg\n",
      "Bild ist gültig: 2154.jpg\n",
      "Bild ist gültig: 2155.jpg\n",
      "Bild ist gültig: 2156.jpg\n",
      "Bild ist gültig: 2157.jpg\n",
      "Bild ist gültig: 2158.jpg\n",
      "Bild ist gültig: 2159.jpg\n",
      "Bild ist gültig: 2160.jpg\n",
      "Bild ist gültig: 2161.jpg\n",
      "Bild ist gültig: 2162.jpg\n",
      "Bild ist gültig: 2163.jpg\n",
      "Bild ist gültig: 2164.jpg\n",
      "Bild ist gültig: 2165.jpg\n",
      "Bild ist gültig: 2166.jpg\n",
      "Bild ist gültig: 2167.jpg\n",
      "Bild ist gültig: 2168.jpg\n",
      "Bild ist gültig: 2169.jpg\n",
      "Bild ist gültig: 2170.jpg\n",
      "Bild ist gültig: 2171.jpg\n",
      "Bild ist gültig: 2172.jpg\n",
      "Bild ist gültig: 2173.jpg\n",
      "Bild ist gültig: 2174.jpg\n",
      "Bild ist gültig: 2175.jpg\n",
      "Bild ist gültig: 2176.jpg\n",
      "Bild ist gültig: 2177.jpg\n",
      "Bild ist gültig: 2178.jpg\n",
      "Bild ist gültig: 2179.jpg\n",
      "Bild ist gültig: 2180.jpg\n",
      "Bild ist gültig: 2181.jpg\n",
      "Bild ist gültig: 2182.jpg\n",
      "Bild ist gültig: 2183.jpg\n",
      "Bild ist gültig: 2184.jpg\n",
      "Bild ist gültig: 2185.jpg\n",
      "Bild ist gültig: 2186.jpg\n",
      "Bild ist gültig: 2187.jpg\n",
      "Bild ist gültig: 2188.jpg\n",
      "Bild ist gültig: 2190.jpg\n",
      "Bild ist gültig: 2191.jpg\n",
      "Bild ist gültig: 2192.jpg\n",
      "Bild ist gültig: 2193.jpg\n",
      "Bild ist gültig: 2194.jpg\n",
      "Bild ist gültig: 2195.jpg\n",
      "Bild ist gültig: 2196.jpg\n",
      "Bild ist gültig: 2197.jpg\n",
      "Bild ist gültig: 2198.jpg\n",
      "Bild ist gültig: 2199.jpg\n",
      "Bild ist gültig: 2200.jpg\n",
      "Bild ist gültig: 2201.jpg\n",
      "Bild ist gültig: 2202.jpg\n",
      "Bild ist gültig: 2203.jpg\n",
      "Bild ist gültig: 2204.jpg\n",
      "Bild ist gültig: 2205.jpg\n",
      "Bild ist gültig: 2206.jpg\n",
      "Bild ist gültig: 2207.jpg\n",
      "Bild ist gültig: 2208.jpg\n",
      "Bild ist gültig: 2209.jpg\n",
      "Bild ist gültig: 2210.jpg\n",
      "Bild ist gültig: 2211.jpg\n",
      "Bild ist gültig: 2212.jpg\n",
      "Bild ist gültig: 2213.jpg\n",
      "Bild ist gültig: 2214.jpg\n",
      "Bild ist gültig: 2215.jpg\n",
      "Bild ist gültig: 2216.jpg\n",
      "Bild ist gültig: 2217.jpg\n",
      "Bild ist gültig: 2218.jpg\n",
      "Bild ist gültig: 2219.jpg\n",
      "Bild ist gültig: 2220.jpg\n",
      "Bild ist gültig: 2221.jpg\n",
      "Bild ist gültig: 2222.jpg\n",
      "Bild ist gültig: 2223.jpg\n",
      "Bild ist gültig: 2224.jpg\n",
      "Bild ist gültig: 2225.jpg\n",
      "Bild ist gültig: 2226.jpg\n",
      "Bild ist gültig: 2227.jpg\n",
      "Bild ist gültig: 2228.jpg\n",
      "Bild ist gültig: 2229.jpg\n",
      "Bild ist gültig: 2230.jpg\n",
      "Bild ist gültig: 2231.jpg\n",
      "Bild ist gültig: 2232.jpg\n",
      "Bild ist gültig: 2233.jpg\n",
      "Bild ist gültig: 2234.jpg\n",
      "Bild ist gültig: 2235.jpg\n",
      "Bild ist gültig: 2236.jpg\n",
      "Bild ist gültig: 2237.jpg\n",
      "Bild ist gültig: 2238.jpg\n",
      "Bild ist gültig: 2239.jpg\n",
      "Bild ist gültig: 2240.jpg\n",
      "Bild ist gültig: 2241.jpg\n",
      "Bild ist gültig: 2242.jpg\n",
      "Bild ist gültig: 2243.jpg\n",
      "Bild ist gültig: 2244.jpg\n",
      "Bild ist gültig: 2245.jpg\n",
      "Bild ist gültig: 2246.jpg\n",
      "Bild ist gültig: 2247.jpg\n",
      "Bild ist gültig: 2248.jpg\n",
      "Bild ist gültig: 2249.jpg\n",
      "Bild ist gültig: 2250.jpg\n",
      "Bild ist gültig: 2251.jpg\n",
      "Bild ist gültig: 2252.jpg\n",
      "Bild ist gültig: 2253.jpg\n",
      "Bild ist gültig: 2254.jpg\n",
      "Bild ist gültig: 2255.jpg\n",
      "Bild ist gültig: 2256.jpg\n",
      "Bild ist gültig: 2257.jpg\n",
      "Bild ist gültig: 2258.jpg\n",
      "Bild ist gültig: 2259.jpg\n",
      "Bild ist gültig: 2260.jpg\n",
      "Bild ist gültig: 2261.jpg\n",
      "Bild ist gültig: 2262.jpg\n",
      "Bild ist gültig: 2263.jpg\n",
      "Bild ist gültig: 2264.jpg\n",
      "Bild ist gültig: 2265.jpg\n",
      "Bild ist gültig: 2266.jpg\n",
      "Bild ist gültig: 2267.jpg\n",
      "Bild ist gültig: 2268.jpg\n",
      "Bild ist gültig: 2269.jpg\n",
      "Bild ist gültig: 2270.jpg\n",
      "Bild ist gültig: 2271.jpg\n",
      "Bild ist gültig: 2272.jpg\n",
      "Bild ist gültig: 2273.jpg\n",
      "Bild ist gültig: 2274.jpg\n",
      "Bild ist gültig: 2275.jpg\n",
      "Bild ist gültig: 2276.jpg\n",
      "Bild ist gültig: 2277.jpg\n",
      "Bild ist gültig: 2278.jpg\n",
      "Bild ist gültig: 2279.jpg\n",
      "Bild ist gültig: 2280.jpg\n",
      "Bild ist gültig: 2281.jpg\n",
      "Bild ist gültig: 2282.jpg\n",
      "Bild ist gültig: 2283.jpg\n",
      "Bild ist gültig: 2284.jpg\n",
      "Bild ist gültig: 2285.jpg\n",
      "Bild ist gültig: 2286.jpg\n",
      "Bild ist gültig: 2287.jpg\n",
      "Bild ist gültig: 2288.jpg\n",
      "Bild ist gültig: 2289.jpg\n",
      "Bild ist gültig: 2290.jpg\n",
      "Bild ist gültig: 2291.jpg\n",
      "Bild ist gültig: 2292.jpg\n",
      "Bild ist gültig: 2293.jpg\n",
      "Bild ist gültig: 2294.jpg\n",
      "Bild ist gültig: 2295.jpg\n",
      "Bild ist gültig: 2296.jpg\n",
      "Bild ist gültig: 2297.jpg\n",
      "Bild ist gültig: 2298.jpg\n",
      "Bild ist gültig: 2299.jpg\n",
      "Bild ist gültig: 2300.jpg\n",
      "Bild ist gültig: 2301.jpg\n",
      "Bild ist gültig: 2302.jpg\n",
      "Bild ist gültig: 2303.jpg\n",
      "Bild ist gültig: 2304.jpg\n",
      "Bild ist gültig: 2305.jpg\n",
      "Bild ist gültig: 2306.jpg\n",
      "Bild ist gültig: 2307.jpg\n",
      "Bild ist gültig: 2308.jpg\n",
      "Bild ist gültig: 2309.jpg\n",
      "Bild ist gültig: 2310.jpg\n",
      "Bild ist gültig: 2311.jpg\n",
      "Bild ist gültig: 2312.jpg\n",
      "Bild ist gültig: 2313.jpg\n",
      "Bild ist gültig: 2314.jpg\n",
      "Bild ist gültig: 2315.jpg\n",
      "Bild ist gültig: 2316.jpg\n",
      "Bild ist gültig: 2317.jpg\n",
      "Bild ist gültig: 2318.jpg\n",
      "Bild ist gültig: 2319.jpg\n",
      "Bild ist gültig: 2320.jpg\n",
      "Bild ist gültig: 2321.jpg\n",
      "Bild ist gültig: 2322.jpg\n",
      "Bild ist gültig: 2323.jpg\n",
      "Bild ist gültig: 2324.jpg\n",
      "Bild ist gültig: 2325.jpg\n",
      "Bild ist gültig: 2326.jpg\n",
      "Bild ist gültig: 2327.jpg\n",
      "Bild ist gültig: 2328.jpg\n",
      "Bild ist gültig: 2329.jpg\n",
      "Bild ist gültig: 2330.jpg\n",
      "Bild ist gültig: 2331.jpg\n",
      "Bild ist gültig: 2332.jpg\n",
      "Bild ist gültig: 2333.jpg\n",
      "Bild ist gültig: 2334.jpg\n",
      "Bild ist gültig: 2335.jpg\n",
      "Bild ist gültig: 2336.jpg\n",
      "Bild ist gültig: 2337.jpg\n",
      "Bild ist gültig: 2338.jpg\n",
      "Bild ist gültig: 2339.jpg\n",
      "Bild ist gültig: 2340.jpg\n",
      "Bild ist gültig: 2341.jpg\n",
      "Bild ist gültig: 2342.jpg\n",
      "Bild ist gültig: 2343.jpg\n",
      "Bild ist gültig: 2344.jpg\n",
      "Bild ist gültig: 2345.jpg\n",
      "Bild ist gültig: 2346.jpg\n",
      "Bild ist gültig: 2347.jpg\n",
      "Bild ist gültig: 2348.jpg\n",
      "Bild ist gültig: 2349.jpg\n",
      "Bild ist gültig: 2350.jpg\n",
      "Bild ist gültig: 2351.jpg\n",
      "Bild ist gültig: 2352.jpg\n",
      "Bild ist gültig: 2353.jpg\n",
      "Bild ist gültig: 2354.jpg\n",
      "Bild ist gültig: 2355.jpg\n",
      "Bild ist gültig: 2356.jpg\n",
      "Bild ist gültig: 2357.jpg\n",
      "Bild ist gültig: 2358.jpg\n",
      "Bild ist gültig: 2359.jpg\n",
      "Bild ist gültig: 2360.jpg\n",
      "Bild ist gültig: 2361.jpg\n",
      "Bild ist gültig: 2362.jpg\n",
      "Bild ist gültig: 2363.jpg\n",
      "Bild ist gültig: 2364.jpg\n",
      "Bild ist gültig: 2365.jpg\n",
      "Bild ist gültig: 2366.jpg\n",
      "Bild ist gültig: 2367.jpg\n",
      "Bild ist gültig: 2368.jpg\n",
      "Bild ist gültig: 2369.jpg\n",
      "Bild ist gültig: 2370.jpg\n",
      "Bild ist gültig: 2371.jpg\n",
      "Bild ist gültig: 2372.jpg\n",
      "Bild ist gültig: 2373.jpg\n",
      "Bild ist gültig: 2374.jpg\n",
      "Bild ist gültig: 2375.jpg\n",
      "Bild ist gültig: 2376.jpg\n",
      "Bild ist gültig: 2377.jpg\n",
      "Bild ist gültig: 2378.jpg\n",
      "Bild ist gültig: 2379.jpg\n",
      "Bild ist gültig: 2380.jpg\n",
      "Bild ist gültig: 2381.jpg\n",
      "Bild ist gültig: 2382.jpg\n",
      "Bild ist gültig: 2383.jpg\n",
      "Bild ist gültig: 2384.jpg\n",
      "Bild ist gültig: 2385.jpg\n",
      "Bild ist gültig: 2386.jpg\n",
      "Bild ist gültig: 2387.jpg\n",
      "Bild ist gültig: 2388.jpg\n",
      "Bild ist gültig: 2389.jpg\n",
      "Bild ist gültig: 2390.jpg\n",
      "Bild ist gültig: 2391.jpg\n",
      "Bild ist gültig: 2392.jpg\n",
      "Bild ist gültig: 2393.jpg\n",
      "Bild ist gültig: 2394.jpg\n",
      "Bild ist gültig: 2395.jpg\n",
      "Bild ist gültig: 2396.jpg\n",
      "Bild ist gültig: 2397.jpg\n",
      "Bild ist gültig: 2398.jpg\n",
      "Bild ist gültig: 2399.jpg\n",
      "Bild ist gültig: 2400.jpg\n",
      "Bild ist gültig: 2401.jpg\n",
      "Bild ist gültig: 2402.jpg\n",
      "Bild ist gültig: 2403.jpg\n",
      "Bild ist gültig: 2404.jpg\n",
      "Bild ist gültig: 2405.jpg\n",
      "Bild ist gültig: 2406.jpg\n",
      "Bild ist gültig: 2407.jpg\n",
      "Bild ist gültig: 2408.jpg\n",
      "Bild ist gültig: 2409.jpg\n",
      "Bild ist gültig: 2410.jpg\n",
      "Bild ist gültig: 2411.jpg\n",
      "Bild ist gültig: 2412.jpg\n",
      "Bild ist gültig: 2413.jpg\n",
      "Bild ist gültig: 2414.jpg\n",
      "Bild ist gültig: 2415.jpg\n",
      "Bild ist gültig: 2416.jpg\n",
      "Bild ist gültig: 2417.jpg\n",
      "Bild ist gültig: 2418.jpg\n",
      "Bild ist gültig: 2419.jpg\n",
      "Bild ist gültig: 2420.jpg\n",
      "Bild ist gültig: 2421.jpg\n",
      "Bild ist gültig: 2422.jpg\n",
      "Bild ist gültig: 2423.jpg\n",
      "Bild ist gültig: 2424.jpg\n",
      "Bild ist gültig: 2425.jpg\n",
      "Bild ist gültig: 2426.jpg\n",
      "Bild ist gültig: 2427.jpg\n",
      "Bild ist gültig: 2428.jpg\n",
      "Bild ist gültig: 2429.jpg\n",
      "Bild ist gültig: 2430.jpg\n",
      "Bild ist gültig: 2431.jpg\n",
      "Bild ist gültig: 2432.jpg\n",
      "Bild ist gültig: 2433.jpg\n",
      "Bild ist gültig: 2434.jpg\n",
      "Bild ist gültig: 2435.jpg\n",
      "Bild ist gültig: 2436.jpg\n",
      "Bild ist gültig: 2437.jpg\n",
      "Bild ist gültig: 2438.jpg\n",
      "Bild ist gültig: 2439.jpg\n",
      "Bild ist gültig: 2440.jpg\n",
      "Bild ist gültig: 2441.jpg\n",
      "Bild ist gültig: 2442.jpg\n",
      "Bild ist gültig: 2443.jpg\n",
      "Bild ist gültig: 2444.jpg\n",
      "Bild ist gültig: 2445.jpg\n",
      "Bild ist gültig: 2446.jpg\n",
      "Bild ist gültig: 2447.jpg\n",
      "Bild ist gültig: 2448.jpg\n",
      "Bild ist gültig: 2449.jpg\n",
      "Bild ist gültig: 2450.jpg\n",
      "Bild ist gültig: 2451.jpg\n",
      "Bild ist gültig: 2452.jpg\n",
      "Bild ist gültig: 2453.jpg\n",
      "Bild ist gültig: 2454.jpg\n",
      "Bild ist gültig: 2455.jpg\n",
      "Bild ist gültig: 2456.jpg\n",
      "Bild ist gültig: 2457.jpg\n",
      "Bild ist gültig: 2458.jpg\n",
      "Bild ist gültig: 2459.jpg\n",
      "Bild ist gültig: 2460.jpg\n",
      "Bild ist gültig: 2461.jpg\n",
      "Bild ist gültig: 2462.jpg\n",
      "Bild ist gültig: 2463.jpg\n",
      "Bild ist gültig: 2464.jpg\n",
      "Bild ist gültig: 2465.jpg\n",
      "Bild ist gültig: 2466.jpg\n",
      "Bild ist gültig: 2467.jpg\n",
      "Bild ist gültig: 2468.jpg\n",
      "Bild ist gültig: 2469.jpg\n",
      "Bild ist gültig: 2470.jpg\n",
      "Bild ist gültig: 2471.jpg\n",
      "Bild ist gültig: 2472.jpg\n",
      "Bild ist gültig: 2473.jpg\n",
      "Bild ist gültig: 2474.jpg\n",
      "Bild ist gültig: 2475.jpg\n",
      "Bild ist gültig: 2476.jpg\n",
      "Bild ist gültig: 2477.jpg\n",
      "Bild ist gültig: 2478.jpg\n",
      "Bild ist gültig: 2479.jpg\n",
      "Bild ist gültig: 2480.jpg\n",
      "Bild ist gültig: 2481.jpg\n",
      "Bild ist gültig: 2482.jpg\n",
      "Bild ist gültig: 2483.jpg\n",
      "Bild ist gültig: 2484.jpg\n",
      "Bild ist gültig: 2485.jpg\n",
      "Bild ist gültig: 2486.jpg\n",
      "Bild ist gültig: 2487.jpg\n",
      "Bild ist gültig: 2488.jpg\n",
      "Bild ist gültig: 2489.jpg\n",
      "Bild ist gültig: 2490.jpg\n",
      "Bild ist gültig: 2491.jpg\n",
      "Bild ist gültig: 2492.jpg\n",
      "Bild ist gültig: 2493.jpg\n",
      "Bild ist gültig: 2494.jpg\n",
      "Bild ist gültig: 2495.jpg\n",
      "Bild ist gültig: 2496.jpg\n",
      "Bild ist gültig: 2497.jpg\n",
      "Bild ist gültig: 2498.jpg\n",
      "Bild ist gültig: 2499.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def check_images_in_directory(directory_path):\n",
    "    # Alle Dateien im Verzeichnis auflisten\n",
    "    filenames = os.listdir(directory_path)\n",
    "    \n",
    "    for filename in filenames:\n",
    "        # Nur .jpg Bilder verarbeiten\n",
    "        if filename.lower().endswith('.jpg'):\n",
    "            filepath = os.path.join(directory_path, filename)\n",
    "            try:\n",
    "                # Bild öffnen und verifizieren\n",
    "                img = Image.open(filepath)\n",
    "                img.verify()  # Überprüft, ob die Datei ein gültiges Bild ist\n",
    "                \n",
    "                print(f\"Bild ist gültig: {filename}\")\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                print(f\"Ungültiges Bild: {filename} - Fehler: {e}\")\n",
    "\n",
    "# Verzeichnis der Bilder\n",
    "path_images = '/home/riccardodandrea/Schreibtisch/Github/SceneDetect/cats_vs_dogs_small/test/dog'\n",
    "\n",
    "# Alle Bilder im Verzeichnis überprüfen\n",
    "check_images_in_directory(path_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*S. 220*\n",
    "\n",
    "Listing 8.12 Displaying curves of loss and accuracy during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*S. 221* \n",
    "\n",
    "Listing 8.13 Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = keras.models.load_model(\"model/convnet_from_scratch.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Test accuracy von 0.693**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der **data_augmentation-Block** erstellt eine Pipeline für die Bildaugmentation, bei der:\n",
    "\n",
    "Zufällige horizontale Spiegelungen durchgeführt werden.\n",
    "Zufällige Rotationen von Bildern im Bereich von -10 bis +10 Grad angewendet werden.\n",
    "Zufälliger Zoom von bis zu 20% durchgeführt wird.\n",
    "\n",
    "Das hilft, das Modell robuster gegen verschiedene Bildorientierungen zu machen und verhindert, dass das Modell nur spezifische Ausrichtungen von Objekten erkennt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*S.221*\n",
    "Listing 8.14 Define a data augmentation stage to add to an image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*S. 222*\n",
    "\n",
    "Listing 8.15 Displaying some randomly augmented training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_dataset.take(1): #welches bild\n",
    "    for i in range(9): # bilder anzahl\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1) # wie viele plots\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "binäre Klassifikationsaufgabe eines CNN Models:\n",
    "- **Input 180 x 180 x 3 Farbkanäle RGB**\n",
    "- **data_augmentation(inputs)** Transormierten bilder mit den bilder inputs gespiegelt, Rotationen und Zoom.\n",
    "- **Reskalierung: (x = layers.Rescaling(1./255)(x))**\n",
    "Die Reskalierung sorgt dafür, dass die Pixelwerte der Bilder von einem Bereich von [0, 255] (die typischen Farbwerte von Bildern) auf [0, 1] skaliert werden.\n",
    "Dies ist wichtig, weil es den Lernprozess stabiler macht und das Modell schneller konvergieren kann, da viele neuronale Netzwerke besser mit kleineren Eingabewerten arbeiten.\n",
    "\n",
    "- **Konvolutionale Schichten (Conv2D)**\n",
    "    - Jede Conv2D-Schicht hat eine bestimmte Anzahl von Filtern (oder Kernels) und eine Kernelgröße (hier 3x3). Diese Filter werden über das Bild geschoben, um lokale Merkmale wie Kanten, Ecken oder Texturen zu extrahieren.\n",
    "    -Die Anzahl der Filter wächst mit den Schichten (32, 64, 128, 256), was darauf hindeutet, dass das Modell zunehmend komplexere Merkmale erlernt, je weiter es in der Tiefe geht.\n",
    "    - activation=\"relu\" bedeutet, dass die ReLU-Aktivierungsfunktion auf die Ausgaben jeder Convolutional-Schicht angewendet wird. ReLU hilft, Nichtlinearitäten in das Modell einzuführen, wodurch es leistungsfähiger wird.\n",
    "\n",
    "- Max-Pooling-Schichten (MaxPooling2D): Nach jeder Convolutional-Schicht folgt eine Max-Pooling-Schicht, die die Dimensionen der Feature-Maps reduziert.\n",
    "- Der Parameter pool_size=2 bedeutet, dass der Pooling-Bereich 2x2 ist. Max-Pooling extrahiert das Maximum aus einem 2x2 Bereich der Feature-Map, was zu einer Reduzierung der Größe und einer Verdichtung der Informationen führt.\n",
    "- Dies hilft, die Rechenleistung zu reduzieren und das Modell robuster gegenüber kleinen Verschiebungen im Bild zu machen.\n",
    "\n",
    "- **Flatten**\n",
    "- Flatten() wird verwendet, um die mehrdimensionalen Ausgaben der letzten Konvolutional- und Pooling-Schicht in einen flachen Vektor umzuwandeln.\n",
    "- Dies ist notwendig, da die nachfolgende dichte Schicht (Dense) nur mit Vektoren arbeitet (nicht mit mehrdimensionalen Tensoren).\n",
    "\n",
    "Dropout-Sicht (Dropout=0.50)\n",
    "- Regulierungstechnik um Overfitting zu verhindern.\n",
    "- Während des Trainings zufällig 50 % der Neuronen in dieser Sicht deaktivert (auf Null gesetzt)\n",
    "- Dies zwingt das Modell, robustere Merkmale zu lernen, da es nicht auf bestimmte Neuronen angewiesen ist.\n",
    "\n",
    "- Ausgabeschicht (Dense)\n",
    "- Dense(1, activation=\"sigmoid\") definiert eine dichte Schicht mit nur einem Neuron und der Sigmoid-Aktivierungsfunktion.\n",
    "- Da es sich um ein binäres Klassifikationsproblem handelt, gibt die \n",
    "    - Sigmoid-Funktion eine Wahrscheinlichkeit zwischen 0 und 1 zurück, die angibt, ob das Bild der Klasse 1 oder Klasse 0 zugeordnet werden soll.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Modell laden\n",
    "model_path = r\"model\\convnet_from_scratch.keras\"\n",
    "convnet_from_scratch = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Modell Zusammenfassung anzeigen\n",
    "convnet_from_scratch.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model nutzen\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bild laden\n",
    "image_path = r\"cats_and_dogs_small\\test\\cats\\1547.jpg\"\n",
    "\n",
    "# Bild auf die gewünschte Eingabegröße skalieren unsere Modell nimmt 180 x 180 x3\n",
    "img = image.load_img(image_path, target_size=(180, 180))\n",
    "\n",
    "# Bild anzeigen\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Bild in ein NumPy-Array umwandeln\n",
    "img_array = image.img_to_array(img)\n",
    "# Das Bild auf die Batch-Dimension erweitern (Modell erwartet eine Batch von Bildern)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "print(img_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersage mit dem geladenen Modell\n",
    "prediction = convnet_from_scratch.predict(img_array)\n",
    "\n",
    "# Vorhersage auswerten\n",
    "# Da es eine binäre Klassifikation (Hund vs. Katze) ist:\n",
    "if prediction[0] > 0.5:\n",
    "    print(\"Das Bild zeigt einen Hund.\")\n",
    "else:\n",
    "    print(\"Das Bild zeigt eine Katze.\")\n",
    "\n",
    "# Ausgabe der Vorhersagewahrscheinlichkeit\n",
    "print(\"Vorhersagewahrscheinlichkeit für Hund:\", prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*S.223*\n",
    "\n",
    "Listing 8.16 Defining a new convnet that includes image augmentation and dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Model: convnet_from_scratch_with_augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modell erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "optimizer=\"rmsprop\",\n",
    "metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*S. 223*\n",
    "\n",
    "Listing 8.17 Training the regularized convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"model/convnet_from_scratch_with_augmentation.keras\",\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_loss\")\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*S.224*\n",
    "\n",
    "Visualisieren und Evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*S. 224*\n",
    "\n",
    "Listing 8.18 Evaluating the model on the test set\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = keras.models.load_model(\n",
    "\"model/convnet_from_scratch_with_augmentation.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"convnet_from_scratch_with_augmentation\" **Test accuracy: 0.795**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model einladen: **\"convnet_from_scratch_with_augmentation\"** und \n",
    "\n",
    "##### Vohersagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Modell laden\n",
    "model_path = r\"model\\convnet_from_scratch_with_augmentation.keras\"\n",
    "model_convnet_from_scratch_with_augmentation = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Modell Zusammenfassung anzeigen\n",
    "model_convnet_from_scratch_with_augmentation.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model nutzen\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bild laden\n",
    "image_path = r\"cats_and_dogs_small\\test\\cats\\1500.jpg\"\n",
    "\n",
    "# Bild auf die gewünschte Eingabegröße skalieren unsere Modell nimmt 180 x 180 x3\n",
    "img = image.load_img(image_path, target_size=(180, 180))\n",
    "\n",
    "# Bild anzeigen (optional)\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Bild in ein NumPy-Array umwandeln\n",
    "img_array = image.img_to_array(img)\n",
    "# Das Bild auf die Batch-Dimension erweitern (Modell erwartet eine Batch von Bildern)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "print(img_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersage mit dem geladenen Modell\n",
    "prediction = model_convnet_from_scratch_with_augmentation.predict(img_array)\n",
    "\n",
    "# Vorhersage auswerten\n",
    "# Da es eine binäre Klassifikation (Hund vs. Katze) ist:\n",
    "if prediction[0] > 0.5:\n",
    "    print(\"Das Bild zeigt einen Hund.\")\n",
    "else:\n",
    "    print(\"Das Bild zeigt eine Katze.\")\n",
    "\n",
    "# Ausgabe der Vorhersagewahrscheinlichkeit\n",
    "print(\"Vorhersagewahrscheinlichkeit für Hund:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Bereits erstelltest Model VGG16 nutzen:\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction consists of using the representations learned by a previously\n",
    "trained model to extract interesting features from new samples. These features are\n",
    "then run through a new classifier, which is trained from scratch.\n",
    "As you saw previously, convnets used for image classification comprise two parts:\n",
    "they start with a series of pooling and convolution layers, and they end with a densely\n",
    "connected classifier. The first part is called the convolutional base of the model. In the\n",
    "case of convnets, feature extraction consists of taking the convolutional base of a previously\n",
    "trained network, running the new data through it, and training a new classifier\n",
    "on top of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "weights=\"imagenet\",\n",
    "include_top=False,\n",
    "input_shape=(180, 180, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_features_and_labels(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for images, labels in dataset:\n",
    "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
    "        features = conv_base.predict(preprocessed_images)\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
    "train_features, train_labels = get_features_and_labels(train_dataset)\n",
    "val_features, val_labels = get_features_and_labels(validation_dataset)\n",
    "test_features, test_labels = get_features_and_labels(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(5, 5, 512))\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "optimizer=\"rmsprop\",\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model/feature_extraction.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_features, train_labels,\n",
    "    epochs=20,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Modell laden\n",
    "model_path = r\"model\\feature_extraction.keras\"\n",
    "feature_extraction = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Modell Zusammenfassung anzeigen\n",
    "feature_extraction.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MobileNetV2 mit den weights von imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v2 as imageio\n",
    "from PIL import Image\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio  \n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.applications.mobilenet_v2 import decode_predictions\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MobileNetV2 = MobileNetV2(weights='imagenet')\n",
    "MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bild laden\n",
    "image_path = r\"shi_zu.jpg\"\n",
    "\n",
    "# Bild auf die gewünschte Eingabegröße skalieren unsere Modell nimmt 180 x 180 x3\n",
    "img = image.load_img(image_path, target_size=(224, 224))\n",
    "\n",
    "# Bild anzeigen\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imageio.imread(r'shi_zu.jpg')\n",
    "\n",
    "# Bild auf die gewünschte Größe (224, 224) skalieren\n",
    "img_resized = Image.fromarray(img).resize((224, 224))\n",
    "\n",
    "# Bild in das numpy Array einfügen\n",
    "data = np.empty((1, 224, 224, 3))\n",
    "data[0] = np.array(img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_input(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = MobileNetV2.predict(data)\n",
    "print('Shape: {}'.format(predictions.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_neuron = np.argmax(predictions[0])\n",
    "print('Most active neuron: {} ({:.2f}%)'.format(\n",
    "    output_neuron,\n",
    "    100 * predictions[0][output_neuron]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, desc, score in decode_predictions(predictions)[0]:\n",
    "    print('- {} ({:.2f}%%)'.format(desc, 100 * score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Fine tune MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SENET \n",
    "Code: https://pytorch.org/hub/pytorch_vision_squeezenet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\n",
    "# or\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_1', pretrained=True)\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "image_path = r\"cats_and_dogs_small\\test\\dogs\\1586.jpg\"\n",
    "\n",
    "# Bild auf die gewünschte Eingabegröße skalieren unsere Modell nimmt 180 x 180 x3\n",
    "img = Image.open(r\"cats_and_dogs_small\\test\\dogs\\1586.jpg\")\n",
    "\n",
    "# Bild anzeigen\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From dir path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(r\"cats_and_dogs_small\\test\\dogs\\1586.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "input_image = Image.open(r\"cats_and_dogs_small\\test\\dogs\\1586.jpg\")\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
    "print(output[0].shape)\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "print(probabilities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Url example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
    "print(output[0].shape)\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "print(probabilities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the categories\n",
    "\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tune SENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Lade das vortrainierte SqueezeNet-Modell\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\n",
    "\n",
    "# Behalte das Basis-Modell bei\n",
    "base_model = model.features  # Das ist die 'Feature'-Extraktionseinheit\n",
    "\n",
    "# Füge neue Schichten für die Klassifikation hinzu\n",
    "num_classes = 5  # Anzahl der Klassen in deinem Datensatz\n",
    "\n",
    "# Neue Klassifikationsschicht\n",
    "new_classifier = nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(1),  # Reduziert die Ausgabedimensionen auf 1x1\n",
    "    nn.Flatten(),  # Wandelt die 2D-Ausgabe in einen 1D-Vektor um\n",
    "    nn.Linear(512, num_classes)  # Die letzte Schicht für die Klassifikation\n",
    ")\n",
    "\n",
    "# Kombiniere das Basis-Modell mit der neuen Klassifikationsschicht\n",
    "model = nn.Sequential(\n",
    "    base_model,\n",
    "    new_classifier\n",
    ")\n",
    "\n",
    "# Initialisiere das Modell für das Training\n",
    "model.train()\n",
    "\n",
    "# Definiere den Optimierer und die Verlustfunktion\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Beispiel für einen Trainingsloop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in dataloader:  # Angenommen, du hast einen DataLoader `dataloader`\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "\n",
    "# Pfad zum Bild\n",
    "image_path = r'cats_and_dogs_small\\test\\dogs\\1515.jpg'  # Gib den vollständigen Pfad zum Bild an\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Processor und Modell laden\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "# Bild verarbeiten\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# Vorhersage machen\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "\n",
    "# Die vorhergesagte Klasse bestimmen\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "\n",
    "# Vorhersage ausgeben\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
